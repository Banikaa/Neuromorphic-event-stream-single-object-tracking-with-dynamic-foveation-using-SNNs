# Neuromorphic event stream single object tracking with dynamic foveation using Spiking Neural Networks
This repository is for the submission of my final Master's Project.


Object tracking is one of the main tasks in computer vision, incorporating three different problems into a single pipeline: object detection, identification and trajectory prediction based on previous behaviour. Traditional cameras struggle with this task due to motion blur, which significantly reduces tracking accuracy and remains one of the most difficult challenges in computer vision. Silicon retinas provide exceptionally high temporal resolution essential for capturing fast-moving objects without motion blur, making neuromorphic data well suited for tracking applications where conventional frame-based approaches fail. The combination of event cameras and Spiking Neural Networks (SNNs) has shown particular promise for tracking fast-moving objects where traditional frame-based approaches struggle due to motion blur and limited temporal resolution. This research presents a complete neuromorphic tracking pipeline using Spiking Neural Networks to process asynchronous event streams from the ATIS Plane dataset, which captures plane aircraft falling at varying velocities. The three-layer SNN architecture proposed maintains persistent membrane states across entire sequences and processes recordings with varying length, mimicking real-world use. This enables the model to learn complex temporal dynamics, unavailable in frame-based methods, while the multi-head outputs provide simultaneous detection, localization, size estimation, and velocity prediction. Key contributions include particle filter enhancement of ground truth annotations to address quality limitations through the addition of Gaussian uncertainty, and a biologically-inspired dynamic foveation system that predicts future object locations to concentrate computational resources on regions of interest. The optimal model achieved 98.16% detection accuracy, 94.27% F1 score, 55.62% mean IoU, and 10.47 pixels centre prediction error, while the foveation mechanism removed 18.4% of events without accuracy degradation. This work demonstrates that combining event cameras, SNNs, and attention mechanisms represents a promising direction for energy-efficient vision systems, providing a foundation for biologically-inspired computer vision.
